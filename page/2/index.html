<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/Sunny7464/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/Sunny7464/css/main.css?v=6.4.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/Sunny7464/images/apple-touch-icon-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/Sunny7464/images/favicon-32x32-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/Sunny7464/images/favicon-16x16-next.png?v=6.4.0">


  <link rel="mask-icon" href="/Sunny7464/images/logo.svg?v=6.4.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/Sunny7464/',
    scheme: 'Muse',
    version: '6.4.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Jiaao &amp; 7">
<meta property="og:url" content="https://jiaaodong.github.io/Sunny7464/page/2/index.html">
<meta property="og:site_name" content="Jiaao &amp; 7">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jiaao &amp; 7">






  <link rel="canonical" href="https://jiaaodong.github.io/Sunny7464/page/2/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Jiaao & 7</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/Sunny7464/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiaao & 7</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/Sunny7464/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/Sunny7464/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/12/03/CS231n笔记6-Neural-Networks-Part-3-Learning-and-Evaluation/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/12/03/CS231n笔记6-Neural-Networks-Part-3-Learning-and-Evaluation/" itemprop="url">
                  CS231n笔记6-Neural Networks Part 3: Learning and Evaluation
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-12-03 05:06:03" itemprop="dateCreated datePublished" datetime="2018-12-03T05:06:03+01:00">2018-12-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:12:59" itemprop="dateModified" datetime="2018-12-18T20:12:59+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>Centered-formula 是二阶近似的导数，可以用$f(x+h)$与$f(x-h)$的傅里叶级数证明</li>
<li>用双精度来做gradient checking</li>
<li>还是关于双精度的问题：有的时候数据太小了，很容易产生数值方面的问题，$1e^{-10}$以下就很不安全了。所以在计算Loss Function的时候可以考虑不处以Batch Size。如果能够放缩的话，$1e^{0}$是浮点数比较密集的地方</li>
<li>反复强调Gradient Check的重要性与 各种方法，以至于只用少数的样本在非常初级的时候去检验，都不一定可靠。</li>
<li>Sanity Check：<ol>
<li>观察最初的Loss Function是不是符合常理，比如10个类别随机给标签，那么每个类别是0.1，cross-entropy应该为$-log(0.1) = 2.302$</li>
<li>更强的正则化会令损失函数增加</li>
<li>过拟合小的子数据集</li>
</ol>
</li>
<li>Batch Size小会令Loss Function的降低过程噪音更大</li>
<li>momentum 的优化方法是在固定的learning rate的基础上，把learning rate作用到一个量上，然后每次累积这个量，也就是说，每一个batch的update不仅受到当前batch的影响，还受到上一个batch的影响：<blockquote>
<p>$v = \mu \times v - learning rate \times grad$<br>$x = x + v$</p>
</blockquote>
</li>
<li>每一次考虑梯度下降的时候就考虑3维空间：参数是2维，Loss Function是第三维，每次更新就是在2维地图选择一个“方向”前进。</li>
<li>关于物理的动能、动量的联想也是很有帮助的。</li>
<li>Learning Rate 有点像速度，如果一开始在距离最优很远的地方，就要有很大的速度去到达最优，但是如果已经距离最优很近了，太大的速度就会在最优周围跳来跳去</li>
<li>二阶矩是用Hessian Matrix代表曲率，曲率越大的地方，就用更小的Learning Rate。问题是，Hessian Matrix的计算量太大，所以就用Quasi-Newton，而不用真正的Newton Method</li>
<li>我们也可以对不同的参数设置不同的Learning Rate</li>
<li>这是Adam方法和Momentum方法很大的不同</li>
<li>Adam主要就是同时考虑均值和方差，分子是均值的moving average，分母是方差的moving average，均值的方向是靠谱方向，方差大的方向是不靠谱的方向。</li>
<li>当梯度初始化为0时候，用了normalization</li>
<li>用一个worker程序来取样hyper-parameters，并将每一个epoch的结果、参数记录在一个checkpoint文件中。用一个master程序来启动、关闭worker，并查看不同参数下的表现。</li>
<li>只用一个validation fold来做交叉验证</li>
<li>用<code>10**uniform(-6,1)</code>来做learning rate和regularization strength</li>
<li>一开始用小epoch，from coarse to fine。</li>
<li>Model Ensembling可以得到更好的效果，不过要考虑成本。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/28/CS231n笔记5-Neural-Networks-Part-2-Setting-up-the-Data-and-the-Loss/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/28/CS231n笔记5-Neural-Networks-Part-2-Setting-up-the-Data-and-the-Loss/" itemprop="url">
                  CS231n笔记5-Neural Networks Part 2: Setting up the Data and the Loss
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-28 05:01:33" itemprop="dateCreated datePublished" datetime="2018-11-28T05:01:33+01:00">2018-11-28</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:13:32" itemprop="dateModified" datetime="2018-12-18T20:13:32+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>Mean subtraction 是一般会做的，相当于把整个点云平移到原点附近</li>
<li>Normalization 仅当不同的Feature是不同的Scale时候更加必要，但是从今天白天对雷达多普勒响应的分类中看，SVM需要Normalize。</li>
<li>PCA 方法常常用来降维，<code>np.dot(X, X.T)</code> 就是矩阵X的covariance matrix。这个矩阵一定是对称的、半正定的，因此可以对其应用奇异值分解。分解后得到了协方差矩阵的特征向量（并且<code>np.linalg.svd</code>所得到的特征向量已经按照对应的特征值由大到小的顺序拍好），所以原来的特征空间可以投影到任意比Feature维度低的空间里。</li>
<li>variance 小的维度是噪声更大的维度。</li>
<li>Whitening 就是把所有维度按照特征值方向投影后，再把每个维度处以该维度的特征值。</li>
<li>PCA和Whitening在DL里基本不需要，但是Normalization和centering很重要。</li>
<li>将PCA和Whitening转换回去？可以通过乘Transormation Matrix的转置</li>
<li>==所有的预处理都要基于训练集的数据，而不是测试集的数据。比如：mean-subtraction 要减去训练集的mean，pca要拿训练集来计算特征向量==</li>
<li>==不能将权值初始化为0！！否则每一个Neuron的输出就成了一样的，反向传播时候函数的更新也变成了一样的。但是实际上神经元是不对称的==。这叫做Asymmetry breaking</li>
<li>可以将权值初始化为标准正态分布与一个很小的数的乘积，但是特别小的初始化值会令权重更新时候的值也变小，在深度学习时候导致收敛变慢。</li>
<li>初始化为标准正太分布后，每个neuron是一个<code>M x N</code>大小的矩阵，共<code>MN</code>个元素，每个元素都满足标准正态分布，但该neuron的输出会因此而拥有更大标准差的分布，所以我们在初始化neuron的时候要根据输入的数量改变初始化正态分布的标准差。主要的原因是因为输入和输出之间的相乘与相加。</li>
<li>三种形式的初始化：<code>w = np.random.randn(n) / sqrt(n)</code>，<code>w = np.random.rand(n) * 1 / (n1 + n2)</code> <code>w = np.random.randn(n) * sqrt(2.0/n)</code>。第三种是为ReLU专门设置的。</li>
<li>bias通常都直接初始化为0</li>
<li>Batch Normalization 可以有效地缓解不良的初始化，而且batch normalization 是一个可微分的过程。这个过程在神经元之后，Non-linearity 之前</li>
<li>从L2-norm regularization的求导可以得出结论：权值在训练过程中缓慢趋近于0</li>
<li>L1 regularization 是显性的特征值挑选</li>
<li>在测试的时候不用Dropout但是要把所有的输出乘以Dropout的系数。因为之前有Dropout的时候，实际上每一层的Activation信号增强了，否则难以达到与没有Dropout时候相同的信号强度</li>
<li>但这个放缩通常被加在training中，除以probability</li>
<li>Cross-entropy 在类别标签非常多的时候不好用，可以用一棵树来实现层级式的判断</li>
<li>如果每个样本的label不是一个单一的数字，而是一个向量，我们可以把损失函数写成两种形式，一种是$max(1 - \delta * label)$，另一种是把问题看成回归问题，将scores向量回归到label向量。</li>
<li>尽量不要构建L2-norm损失函数，因为在差距较大的时候会得到非常大的更新值，而且这个时候要求具体值的精确度，而不像softmax——只要求数量级之间的关系对了就行。</li>
<li>在遇到回归问题时候，先考虑能不能离散化为分类问题。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/28/C-Primer-Plus-学习笔记2：分支语句和逻辑运算符/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/28/C-Primer-Plus-学习笔记2：分支语句和逻辑运算符/" itemprop="url">
                  C++ Primer Plus 学习笔记2：分支语句和逻辑运算符 
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-28 02:50:59" itemprop="dateCreated datePublished" datetime="2018-11-28T02:50:59+01:00">2018-11-28</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:14:23" itemprop="dateModified" datetime="2018-12-18T20:14:23+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>最近总在看基础，基础的深度学习，基础的语言，基础的数据结构与算法，真的是很无聊。</p>
<ul>
<li><code>&amp;&amp;</code> <code>||</code>的优先级比关系运算符低</li>
<li><code>i++&lt;6||i==j</code>如果在这一句之前<code>i=10</code>，那么当<code>i</code>与<code>j</code>比较的时候，<code>i=11</code>。</li>
<li><code>17&lt;age&lt;35</code>不会报编译错误，但是将恒为<code>true</code>。</li>
<li><code>!</code>的优先级比关系因算符和算术运算符都高，因此要对表达式求反必须用<code>!(x&lt;1)</code>。</li>
<li><code>&amp;&amp;</code>的优先级高于<code>||</code>。</li>
<li><code>#include&lt;cctype&gt;</code> 可以用<code>isalpha(ch)</code>、<code>ispunct(ch)</code>、<code>isspace(ch)</code>、<code>isdigits(ch)</code>、<code>isuper</code>来做一些与字符有关的测试。也有<code>toupper</code>和<code>tolower</code>。</li>
<li>C++中唯一一个需要三个数的运算符是<code>?:</code></li>
<li><code>switch</code>一定要搭配<code>break</code>来用，<code>case</code>只是行标签，不会令程序自动停下。</li>
</ul>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/27/CS231n笔记4-Neural-Networks-Part-1-Setting-up-the-Architecture/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/27/CS231n笔记4-Neural-Networks-Part-1-Setting-up-the-Architecture/" itemprop="url">
                  CS231n笔记4-Neural Networks Part 1: Setting up the Architecture
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-27 05:23:57" itemprop="dateCreated datePublished" datetime="2018-11-27T05:23:57+01:00">2018-11-27</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:15:02" itemprop="dateModified" datetime="2018-12-18T20:15:02+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>Regularization 在神经网络中可以被解释为 Gradual Forgetting。</li>
<li>Softmax是泛化版本的Sigmoid</li>
<li>Softmax可以作为一个neuron的firing rate</li>
<li>Sigmoid的问题：<ol>
<li>Saturation</li>
<li>Non zero-centered</li>
</ol>
</li>
<li>tanh 和sigmoid 的关系：<br>  $tanh(x) = 2* \sigma(2x) - 1$</li>
<li>ReLU 是会导致梯度消失的，从而大面积的神经元“死亡”，因此出现了Leaky ReLU。</li>
<li>Maxout：是ReLU和Leaky ReLU的泛化，但参数增加了一倍</li>
<li>实践中怎么选择：用ReLU，但是注意Learning Rate，同时尽量监控网络中死掉的神经元。永远不用sigmoid。</li>
<li>有一层Hidden Layer的神经网络是Universal Approximator</li>
<li>与CNN相比，全连接网络对于层数的依赖没有那么明显（但3层一般比2层强）这有可能是因为CNN的分层体系</li>
<li>层数太多了 Capacity就增强了，但层数太多了就可能学到数据中的噪音，这就是过拟合。</li>
<li>实际上，用其他技巧来防止overfitting，而不是减少网络复杂度。（比如可以用L2 regularization, dropout, input noise）</li>
<li>小的神经网络的解容易被困在局部最优，而且那些局部最优都不是很好。每次得到的解的方差很大。</li>
<li>大的神经网络不好训练，一开始会有很多的解，但是当最优解被找到时候，是比较好的局部最优，而不是很依赖于随机初始化。</li>
<li></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/23/CS231n笔记3-Backpropagation-Intuitions/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/23/CS231n笔记3-Backpropagation-Intuitions/" itemprop="url">
                  CS231n笔记3-Backpropagation, Intuitions
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-23 05:06:20" itemprop="dateCreated datePublished" datetime="2018-11-23T05:06:20+01:00">2018-11-23</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:15:33" itemprop="dateModified" datetime="2018-12-18T20:15:33+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>如果我们有了函数$f(W, \vec x)$，我们既关心$f$对$W$的导数，因为我们需要更新的就是$W$，也关心$f$对$\vec x$的导数，因为我们要反向传播。<blockquote>
<p>The derivative on each variable tells you the sensitivity of the whole expression on its value.</p>
</blockquote>
</li>
<li>微分是完完全全的局部运算，每一个节点只需要计算该节点的输出对每一个输入的微分。只有当Forward Pass结束了，Backward Pass开始时候，每个节点的微分才被链式法则连接起来得到改节点对Loss Function的导数。</li>
<li>Sigmoid函数也是把结果压缩到[0, 1]之间，其导数是$(1-\sigma(x))\sigma(x))$。</li>
<li>Intuition of back-propagation：加法同等程度地传播梯度、max函数把梯度重新定向到更大的输入，乘法比较复杂，不太intuitive，还是不强行解释了。</li>
<li>因为乘法中的back propagation是和输入的数量级有关的，所以数据的预处理很重要，如果一个很大的数和一个很小的数相乘，反向传播时候，很大的输入得到很小的梯度，很小的输入得到很大的梯度。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/23/CS231n笔记2-Optimization-Stochastic-Gradient-Descent/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/23/CS231n笔记2-Optimization-Stochastic-Gradient-Descent/" itemprop="url">
                  CS231n笔记2-Optimization: Stochastic Gradient Descent
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-23 04:10:35" itemprop="dateCreated datePublished" datetime="2018-11-23T04:10:35+01:00">2018-11-23</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:16:08" itemprop="dateModified" datetime="2018-12-18T20:16:08+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>介绍了一种在高维空间可视化Loss Function的方法：随机挑选一个参数向量，如CIFAR-10的参数$W$为 $3072 * 10$。然后选定一个$\alpha$和一个向量$\vec u$，然后计算不同的$\alpha$值下参数$W+\alpha\vec u$得到的Loss Function。如果想要二维可视化，就选定$\alpha$ 、$\beta$和$\vec u$。</li>
<li>关于凸优化的问题——用只有一个Feature的数据举例子，找到某一个参数W与Loss的关系，是被0所截断的直线之和的平均。</li>
<li>但是NN是非凸的。</li>
<li>==补充复习一下Convex的定义==</li>
<li>斯坦福的课质量真的是高，贵在思路清晰：<blockquote>
<p>Strategy #1: A first very bad idea solution: Random search<br>Strategy #2: Random Local Search<br>Strategy #3: Following the Gradient</p>
</blockquote>
</li>
<li>代码技巧：用<code>np.nditer</code>来遍历矩阵内部所有元素。</li>
<li>Learning Rate 的重要性。</li>
<li>为什么可以用 mini-batch：因为数据是correlated的。粗略的证明：假设我们有1000个classes，每一个class中有1200张完全一样的图片，那么我们用120万张图片训练出来的结果与每个class各一张图片训练出来的结果是一样的。</li>
<li>使用2的倍数做为每个batch中数据的数量可以令向量化的运算更快。</li>
<li>具体用多少，还要考虑内存的限制。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/22/如何令ros-melodic能够兼容ros-indigo的message/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/22/如何令ros-melodic能够兼容ros-indigo的message/" itemprop="url">
                  如何令ros melodic能够兼容ros indigo的message
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-22 17:01:52" itemprop="dateCreated datePublished" datetime="2018-11-22T17:01:52+01:00">2018-11-22</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:16:45" itemprop="dateModified" datetime="2018-12-18T20:16:45+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>问题描述</strong>：从ros indigo记录下来的rosbag遇到ros melodic就会报以下错误：<br><code>Client wants topic xxxxx to have datatype/md5sum [xxxxx], but our version has [xxxxx]. Dropping connection</code></p>
<p><strong>问题分析</strong>：这是因为indigo的message与melodic的message不兼容导致的，是ros的版本问题。我拿到的rosbag是indigo下记录的rosbag，而我的node运行环境是ros melodic。</p>
<p><strong>思路</strong>：改所有的client，遇到一个改一个，因为rosbag是没办法改的了。</p>
<ol>
<li>从github下载Indigo的marker message</li>
<li>改node的<code>#include</code>部分</li>
<li>将<code>Marker.msg</code>与<code>MarkerArray.msg</code>放到<code>catkin_ws</code>的<code>src/[node name]/msg/</code>下</li>
<li>改<code>CMakeLists.txt</code></li>
<li>删除<code>build</code> 和 <code>devel</code>，重新<code>catkin_make</code></li>
</ol>
<p><strong>注意</strong>：<br>只有自己写的node可以这样改，强烈不推荐用同样的方法改rviz，因为rviz是用的std_msgs。但是我们又不能去改std_msgs，因为这样将会把今后所有用到std_msgs的node都改为indigo的msg。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/22/C-Primer-Plus-学习笔记1：循环结构/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/22/C-Primer-Plus-学习笔记1：循环结构/" itemprop="url">
                  C++ Primer Plus 学习笔记1：循环结构
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-22 14:37:27" itemprop="dateCreated datePublished" datetime="2018-11-22T14:37:27+01:00">2018-11-22</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:17:22" itemprop="dateModified" datetime="2018-12-18T20:17:22+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>For 循环中省略了测试条件时，将认为条件为true。</li>
<li><code>clock_t</code>为系统时间的类型名的别名，因此无论系统时间是<code>long</code> 还是 <code>unsigned long</code>，都可以用<code>clock_t</code>声明。<code>CLOCKS_PER_SEC</code>定义了系统时间与秒的换算关系。</li>
<li><code>typedef</code>与<code>#define</code>的区别是<code>define</code>在声明多个变量时候只能拿别名替换一次，如果遇到<code>#define byte char*</code>然后用<code>byte a,b</code>声明两个变量，就会变为<code>char* a,b</code>。这就是预处理器的作用——讲代码做一些自动的“复制粘贴”。</li>
<li><p>C++11开始提供了基于范围的<code>for</code>循环，主要用于循环容器变量内部的值。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> x: &#123;<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>&#125;)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">cout</span>&lt;&lt;x&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>三种不同的输入字符的方法进行比较（==以后应该单独开一个博客写==）</p>
<ul>
<li><code>cin</code>忽略空格和换行符，即使输入了也不会读取。发送给<code>cin</code>的输入被存到缓冲区，只有在用户按下回车后，输入的内容才会发送给程序。</li>
<li><code>cin.get(ch)</code>将读取一行输入，然后将其赋值给<code>ch</code>。这种输入方式仍然将输入先存到缓冲器，按下回车后发送给程序。 </li>
</ul>
</li>
<li>UNIX通过<code>ctrl+D</code>在键盘模拟文件尾条件。</li>
<li>如果要想修改函数外的值，一定要在声明的时候将该参数声明为引用，或者传递该参数的地址。</li>
<li><p>因为C++支持输入输出的重定向，所以如果输入的是文件，我们就需要检测文件的EOF（end of file）。如何检测呢？最常见的方法是：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cin</span>.get(ch);</span><br><span class="line"><span class="keyword">while</span>(<span class="built_in">cin</span>.fail()==fail)</span><br><span class="line">&#123;</span><br><span class="line">	...</span><br><span class="line">	<span class="built_in">cin</span>.get(ch);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>更高效的方法是：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="built_in">cin</span>.get(ch)&#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>因为<code>cin.get(ch)</code>的返回值是<code>cin</code>，而<code>cin</code>会在需要<code>bool</code>值的位置自动返回<code>bool</code>量，如果成功则为<code>true</code>。</p>
</li>
<li>EOF是一个已经定义好的常量，如果用<code>cin.get()</code>函数，那么直接把新读取的字符与EOF做比较就可以了。注意：有些时候不允许将<code>char</code>类型与EOF作比较，那时需要强制类型转换到<code>int</code>。</li>
<li>赋值语句的值为左操作数的值</li>
<li>用<code>cin.get(ch)</code>更加符合面向对象的原则，可以将多个调用串联起来，因为每次<code>cin.get(ch)</code>都会返回一个<code>cin</code>对象，所以<code>cin.get(ch1).get(ch2)</code>是合法的。</li>
<li>当每一行初始化的数组长度不同时（主要指的是char数组，即字符串），可以将长度不同的字符串组成的数组初始化为<code>char</code>指针数组。</li>
<li><code>cin</code>忽略空格、换行符和制表符。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/22/CS231n笔记1-Linear-Classifier-Support-Vector-Machine-Softmax-Classifier/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/22/CS231n笔记1-Linear-Classifier-Support-Vector-Machine-Softmax-Classifier/" itemprop="url">
                  CS231n笔记1-Linear Classifier: Support Vector Machine, Softmax Classifier
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-22 05:29:46" itemprop="dateCreated datePublished" datetime="2018-11-22T05:29:46+01:00">2018-11-22</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:18:08" itemprop="dateModified" datetime="2018-12-18T20:18:08+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>Linear classifier is a template matching. 这里的线性分类器就是相当于给每一个Feature一个权值，这个权值其实是一个尺寸与图片一样大小的Filter。记得一个结论：Filter的样子往往就是你要Filter出的东西的样子，所以学习出的权值本身就是要学习的图片模板。</li>
<li>Normalization. 归一化的作用要在反向传播的时候才能显现出来。</li>
<li>Multi-class SVM loss. 目标是为了让正确的类别的分数比错误的类别的分数大出Delta值，如果已经大出Delta了，那就不管了。</li>
<li>Regularization. 正则化的目的是防止过拟合，而L2 penalty的作用就是让权重更加diffuse。</li>
<li>其实hinge loss中的margin与正则化中的lambda是一个作用，都是表达的weights与loss的trade-off。因此hinge loss中的delta可以直接用1.</li>
<li>数据稳定性：在用softmax的时候要将所有的scores减去他们的最大值再取指数运算。</li>
<li>cross-entropy与KL divergence是等效的（在one hot encoding的前提下），因为delta function的entropy是0。这里的Delta function就是1-hot encoding向量。</li>
<li>光看cross-entropy可以理解为概率中的MLE，如果是带有正则的cross-entropy可以理解为有gaussian distribution a posterier的MAP。</li>
<li>cross-entropy loss从不会对已经训练出的分布“满意”，永远在找更加接近的。而SVM一旦对margin“满意”了（即所有样本正确类别的score都比错误类别的score至少大出delta值了），那么Hinge loss就不再增加了。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiaaodong.github.io/Sunny7464/Sunny7464/2018/11/09/C-PrimerPlus笔记-1/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jiaao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/Sunny7464/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiaao & 7">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Sunny7464/2018/11/09/C-PrimerPlus笔记-1/" itemprop="url">
                  C++PrimerPlus笔记-1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-09 05:24:26" itemprop="dateCreated datePublished" datetime="2018-11-09T05:24:26+01:00">2018-11-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-12-18 20:18:59" itemprop="dateModified" datetime="2018-12-18T20:18:59+01:00">2018-12-18</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>如果要让cout打印数组或者字符的地址，需要把该地址强制类型转换为其他的地址类型，如<code>int*(ptr)</code>，否则<code>cout</code>遇到字符地址就会直接打印所存的字符。</li>
<li>在声明一定长度的字符串时候要用<code>new char[strlen() + 1]</code>来考虑空字符。</li>
<li>类的成员用<code>-&gt;</code>引用是因为有时候用指针传递/创建类的时候，不知道类的名称，没办法用<code>.</code>来访问类成员。如果不用<code>-&gt;</code>也可以<code>(*ptr).element</code>。</li>
<li>C++的内存使用：自动存储、静态存储、动态存储。</li>
<li></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/Sunny7464/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/Sunny7464/">1</a><span class="page-number current">2</span><a class="page-number" href="/Sunny7464/page/3/">3</a><a class="extend next" rel="next" href="/Sunny7464/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Jiaao</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/Sunny7464/archives/">
                
                    <span class="site-state-item-count">27</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              

              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiaao</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Muse</a> v6.4.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/Sunny7464/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/Sunny7464/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/Sunny7464/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/Sunny7464/js/src/utils.js?v=6.4.0"></script>

  <script type="text/javascript" src="/Sunny7464/js/src/motion.js?v=6.4.0"></script>



  
  

  

  


  <script type="text/javascript" src="/Sunny7464/js/src/bootstrap.js?v=6.4.0"></script>



  



  










  





  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
